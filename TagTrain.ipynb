{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8605,"status":"ok","timestamp":1662272100802,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"lK06IIsPmCA9"},"outputs":[],"source":["%%capture\n","!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4872,"status":"ok","timestamp":1662272105664,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"zDgy5SoFnw8G"},"outputs":[],"source":["%%capture\n","!pip install datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1662272105665,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"haVovTi755LH"},"outputs":[],"source":["import transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1662272105665,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"nMufXl0oTHIx"},"outputs":[],"source":["model_checkpoint = \"xlm-roberta-base\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["28879e3fe3b1488fb785bcbaf584bc1b","5e82f4fd2213482f8400011a12b518eb","47c4fd7430994099a91fa54f2b6299b0","9839295520e94413ac059f147c382018","c50bac4aa0f1496c8136905e27472117","f698468850ca4480910ece2de82b6e1b","443955091d994cd9843334c73ff416e6","9582042967a94aaa87113c654744b919","7a5656f4f4714aeda96b1587b7e19146","50eaa07232c74de7b76826f1d2275ed7","aedc0019b5da460e9c052008f63f7e48","a6999ccf23bf4ba7b5c9301d990f901e","43e4f37d63ca4df89aa4b82450519058","48d519949dde44ccbcef3393f76a6658","2ef673b32ce8446bbc5d6362a3c57641","dfab77ae6968406cab4afcb599116377","4944619a6bc04e31a340e9b3e3700e5b","a35a19ce8af3492784190c12c23725f6","d3a351e6a0064f6bb5129b2d6946bc52","79be4808516c4a80b890727534f1aa94","943315f7b7f344839908753c47ab83b9","eeba2a1fd053457694dea950a8325656","a593cd77d7a243ec963da4c0acdad8f0","892b21bb700145559fc7482f5faa9384","0859a9e697e444a2a50213bd85da9449","e936f05dda5b48fb97c6b8ee3a7b5f6f","f168108689174d5baccc2da39ae7b1c7","785b51e6dc844bfb82a09298b850cf3c","f069e7e99baa4aa8b91c0087bf22eb54","a8f6bff4a2c34d50a8f045e0f895a025","547ca38578fb48f19b4c0f280b9902ab","78142dddfa0d423191028245e1aedcc4","20e3dab7c5d64317ae5069b7f3fcf4e0"]},"executionInfo":{"elapsed":5729,"status":"ok","timestamp":1662272111389,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"597jvZfwWl_d","outputId":"0b16f2be-e308-4a76-e124-eb9f41168df5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28879e3fe3b1488fb785bcbaf584bc1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading sentencepiece.bpe.model:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6999ccf23bf4ba7b5c9301d990f901e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a593cd77d7a243ec963da4c0acdad8f0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["512"]},"metadata":{},"execution_count":5}],"source":["from transformers import  AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n","tokenizer.model_max_length"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["429b9cfc184d4c85b6aef57da76848fa","02b8e4d4fc79451193a21a73f0f656a5","c9c6b451a07340b58f3fb73536e03313","c167ce9ddc9f4733a8b369876c540694","06f402a9bbb44987ad9604f6ea51a4e4","c67d3853eed246f5a88056615daf36bf","ef6062ed8a3a48d182d07f6aaec5f2b0","808345a14b204a8f9f33c0493ee49a6d","0963e2bd8d8043f68b91d645f00a3624","bb4cd8803f5a41008f2a72e0c89e3987","f95e8125948a45099aa6d2931eed9a28","fb51f8bcc63340a59361d0ab63cdc591","7c3b5ff235ad4507b9f785739ad863c0","d6b44be109fa4f8eaef31cdcabad0674","f6791067b6a2407390d2d3d1f78043cb","43bd55f0170448ba87b3f3810b42c2fd","7e97b03dde7f4832a7169b09a5bf8c87","a31387ed7b7e4665a1ca1f4ec45c5e1a","e7c42801e61d4a93a5517770c1968b03","ad21fb9638134373b537c11605abc425","7d5cf4f4c9b04f4b855e1c7853bbb0bd","d4593bd1787c4cbebc6efc7fdd1a85d6","cfe16b693e1e413fa6b8a567f039157e","81d94499696348c6840d4cf609bfcf53","47784786ecaf4e1b97f50a48660c4f7e","956584d6c8184b19bc92578a0ad97527","73873319ce95414d9dd1af3504a77a67","64aedabc2bb2424e9137e2d59e190f63","be89fafa82c34190ab8a53a3a810b6f1","3fadd0eff9c64eed82c9584a12232a55","8df04cc4fc084a97acaf9c434bc0d4d8","b1999b6fbe97418ba388921c70b35818","8575b18e664743cab33f7475fd887400","f9a791e0198e4f3192f469c92938a58b","39d0057e90fa489bb20d805903fe1f26","9488ffd9b1bf449591243f22367ee611","12d70e7422214ce2acf516a6b0005618","88ea6d11f0914b2cb09b7199dbf809d8","cbf3c61e40e54c15bca45a21e3b7abaa","73da85046f0d429b9c88bea4624a14d5","e2be3b2b17414bd6824e4c3c79278115","617024cf9cff4720a1b5a8968ad84d65","03ce2311df62459085060e4e88f965ad","501ade53fb144033bfdf9f359cfaa6ca","2ad9be9be4fc4c4ebb82d6ca718c527d","138d6c4f7cbf47bd90d837e1b92e689b","1e206ef7df2a4ffea00f6c6a16b6cb6f","23a526b49f23434c9feb7bfe0e85b06e","70abcccb6ff2495587c922eb0b194f75","2e5ccd5cc0ea48249672db69e0171e6a","98c54377767e4d4ba4d94a040eb2ffc6","68512c02d2724197a6409339cbb8aa07","9460bdc23d544608a47bb297649be013","5c71c557504c48edb5133db70a427a98","7fcbc48487204ac597f572e1549af1d5"]},"executionInfo":{"elapsed":221646,"status":"ok","timestamp":1662272333028,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"IvixGBK2Hv-t","outputId":"ff82dd7a-7913-4e9b-cf37-636748f4239d"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:No config specified, defaulting to: load_dataset/token_tagging\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset load_dataset/token_tagging to /root/.cache/huggingface/datasets/load_dataset/token_tagging/1.0.0/7c799514eb3c22c21d4f96973757a13e4b85d4337ef06fce5d400a82aadcc856...\n","['/content/drive/MyDrive/Colab Notebooks/corpus/big_dataset.txt', '/content/drive/MyDrive/Colab Notebooks/corpus/gold_corpus_test.txt']\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429b9cfc184d4c85b6aef57da76848fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb51f8bcc63340a59361d0ab63cdc591"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['/content/drive/MyDrive/Colab Notebooks/corpus/big_dataset.txt', '/content/drive/MyDrive/Colab Notebooks/corpus/gold_corpus_test.txt']\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe16b693e1e413fa6b8a567f039157e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a791e0198e4f3192f469c92938a58b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset load_dataset downloaded and prepared to /root/.cache/huggingface/datasets/load_dataset/token_tagging/1.0.0/7c799514eb3c22c21d4f96973757a13e4b85d4337ef06fce5d400a82aadcc856. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad9be9be4fc4c4ebb82d6ca718c527d"}},"metadata":{}}],"source":["from datasets import load_dataset, load_metric\n","\n","toke_tagging_dataset = load_dataset('drive/MyDrive/Colab Notebooks/load_dataset.py')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1662272333028,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"kFP5hUjD3MT0"},"outputs":[],"source":["label_list = toke_tagging_dataset['train'].features['labels'].feature.names"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["cc8631dc0d344b048ef734b96b2d75a8","2513dec200794a9fb78929457fb533b0","50df7d4bbbe249148babf585e7469637","1a06e2cb4108427f958602f10a0508ac","ea498309b9f24d7c8f41c0bdc18b90b3","41d7492f6f4a4e249b0d3830f4e15e32","90737b5e718e4cb9bbf9a6ee5a42ee71","b0b34427655f46f2a05a4c11bd97c115","9f3b963da7b144aeaf6a5cf62a7a385c","6d5655a895454323b058931b5662400e","2c107eca5f3747dda87ee828cbbada0a"]},"executionInfo":{"elapsed":23062,"status":"ok","timestamp":1662272356085,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"AFZuRh9zFQjl","outputId":"503bb56a-3121-43cc-e8b7-a4b8c036a04f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc8631dc0d344b048ef734b96b2d75a8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = transformers.AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=3)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2233,"status":"ok","timestamp":1662272358315,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"A1-u1AUatKqZ"},"outputs":[],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n","task = 'error_detection'\n","batch_size = 16\n","\n","args = transformers.TrainingArguments(\n","    f\"{model_name}-finetuned-{task}\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    save_total_limit = 1,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1662272358751,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"uzQQ-O1hxe9c"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5140,"status":"ok","timestamp":1662272363887,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"UiRlO7bM8uWO","outputId":"65a2dbe8-25c3-4cc6-ffab-cfe8719037b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=3aaddeb9ec7bb6dd5b8a13d69c99963220c5293d35e10348f74cdcf8f2562a3f\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["!pip install seqeval"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["066cb7aa7fbb460cbce99fb5f6a8ae92","4ae72080dbc846918ccd235faf391ef4","0ab0af85f99144748eb57ca143c680fd","ce78942c3eb8499c8994c2755d4c7c31","998550dc2ba44952a7c04ab5521146ac","8f2022651dcc44d3a9fe19b51dcb07f6","d98de1d9171441e6a3184f9e5578036f","a5945adfcfa1451cb3870f00678ddd17","9283912d427f4e2ab90c505245eb1c29","dbdc89f42e0f45318e4f458f7e7ed0d3","20ca672fff9645f4805a6adb20b4cd48"]},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1662272364738,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"jRXC7XV-zpCT","outputId":"96311d6e-58b7-41e3-dfdb-94ffb217b192"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066cb7aa7fbb460cbce99fb5f6a8ae92"}},"metadata":{}}],"source":["metric = load_metric(\"seqeval\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1662272364739,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"s8aBmhA381Lh","outputId":"df341414-8879-49ef-c0d0-50422b11f584"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n"," 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n"," 'labels': Sequence(feature=ClassLabel(num_classes=3, names=['ok', 'dif', 'del'], id=None), length=-1, id=None)}"]},"metadata":{},"execution_count":13}],"source":["toke_tagging_dataset['train'].features"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1662272364739,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"2wTaypLd4gVh"},"outputs":[],"source":["example = toke_tagging_dataset[\"train\"][4]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1662272364740,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"O4ysrG334LJo","outputId":"aac0f355-e7d8-4b34-fa07-4bb13aa2dccb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ok seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: dif seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: del seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"]},{"output_type":"execute_result","data":{"text/plain":["{'el': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 4},\n"," 'if': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 7},\n"," 'k': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 9},\n"," 'overall_precision': 1.0,\n"," 'overall_recall': 1.0,\n"," 'overall_f1': 1.0,\n"," 'overall_accuracy': 1.0}"]},"metadata":{},"execution_count":15}],"source":["labels = [label_list[i] for i in example['labels']]\n","metric.compute(predictions=[labels], references=[labels])"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1662272364740,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"4RT3b1bC_WeJ","outputId":"e9dc66b2-49af-4972-850c-a9fc8e9f3c8c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 833571\n","})"]},"metadata":{},"execution_count":16}],"source":["toke_tagging_dataset['train']"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1662272364741,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"OL5yEZHi_X9R","outputId":"5ac28825-6be5-464a-ff43-e840a972bb94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 1519\n","})"]},"metadata":{},"execution_count":17}],"source":["toke_tagging_dataset['validation']"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6137,"status":"ok","timestamp":1662272370868,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"z2hrgtI-ZUk8","outputId":"899f404a-54eb-44f2-8263-3b3608d09a45"},"outputs":[{"output_type":"stream","name":"stdout","text":["3939584\n","3098914\n","448322\n","392348\n"]}],"source":["ok = 0\n","dif = 0\n","dell = 0\n","\n","for tags in  toke_tagging_dataset['train'][:100000]['labels']:\n","  for tag in tags:\n","    if tag == 0:\n","      ok +=1\n","    if tag == 1:\n","      dif +=1\n","    if tag == 2:\n","      dell += 1\n","\n","total = (ok + dif + dell)\n","print(total)\n","print(ok)\n","print(dif)\n","print(dell)\n","\n","weights = [1, 7, 7.9]"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1662272370869,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"RKs48iCr1rre","outputId":"b198b6ec-05e7-4e44-b3c9-fc349cfdac2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n","6.9122505699028824\n","7.8983810290864245\n"]}],"source":["print(ok/ok)\n","print(1/(dif/ok)) #6.5\n","print(1/(dell/ok)) #7.5"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662272370869,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"PM4FZSRk4tQd"},"outputs":[],"source":["import numpy as np\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3178,"status":"ok","timestamp":1662272374042,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"BUuBeZAwvC9w","outputId":"46c83d49-00a6-4546-a2e6-60d750fc0a09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"]}],"source":["!pip install torch"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1662272374043,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"TRJJ6g5bshbB"},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import Trainer\n","\n","\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([7, 7, 1.0], device='cuda'))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":7762,"status":"ok","timestamp":1662272381802,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"V2f8oIx35fRh"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=toke_tagging_dataset[\"train\"],\n","    eval_dataset=toke_tagging_dataset[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1662272381802,"user":{"displayName":"Nicolae Rosca","userId":"09067692646217768074"},"user_tz":-180},"id":"svxPtWE_yvXo","outputId":"fd976d19-375a-4d11-9d18-bbff571aca9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-f4d36d4f-b059-9acb-6a1f-9d748b4160a8)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2oOHRgQW9qFO","outputId":"122915e4-a55d-4c34-aad6-01d7e5860a0f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 833571\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 260495\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='138625' max='260495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [138625/260495 8:36:48 < 7:34:21, 4.47 it/s, Epoch 2.66/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.172800</td>\n","      <td>0.559913</td>\n","      <td>0.353931</td>\n","      <td>0.233314</td>\n","      <td>0.281236</td>\n","      <td>0.915083</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.146100</td>\n","      <td>0.585062</td>\n","      <td>0.371366</td>\n","      <td>0.227194</td>\n","      <td>0.281917</td>\n","      <td>0.919668</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-1000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-1500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-2000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-2500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-3000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-3500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-4000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-4500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-5000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-5500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-6000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-6500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-7000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-7500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-8000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-8500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-9000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-9500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-10000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-10500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-11000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-11500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-12000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-12500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-13000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-13500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-14000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-14500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-15000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-15500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-16000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-16500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-16000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-17000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-17500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-18000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-18500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-19000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-19500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-19000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-20000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-20500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-20500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-20000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-21000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-20500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-21500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-21500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-21000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-22000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-21500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-22500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-22500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-22000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-23000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-22500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-23500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-23500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-23000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-24000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-23500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-24500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-24500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-24000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-25000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-24500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-25500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-25500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-25000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-26000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-25500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-26500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-26500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-26000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-27000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-26500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-27500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-27500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-27000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-28000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-27500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-28500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-28500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-28000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-29000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-28500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-29500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-29500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-29000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-30000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-29500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-30500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-30500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-30000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-31000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-30500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-31500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-31500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-31000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-32000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-31500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-32500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-32500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-32000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-33000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-32500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-33500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-33500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-33000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-34000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-33500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-34500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-34500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-34000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-35000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-34500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-35500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-35500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-35000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-36000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-35500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-36500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-36500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-36000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-37000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-36500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-37500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-37500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-37000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-38000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-37500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-38500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-38500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-38000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-39000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-38500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-39500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-39500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-39000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-40000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-39500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-40500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-40500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-40000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-41000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-40500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-41500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-41500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-41000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-42000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-41500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-42500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-42500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-42000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-43000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-42500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-43500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-43500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-43000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-44000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-43500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-44500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-44500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-44000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-45000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-44500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-45500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-45500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-45000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-46000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-45500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-46500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-46500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-46000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-47000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-46500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-47500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-47500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-47000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-48000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-47500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-48500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-48500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-48000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-49000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-48500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-49500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-49500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-49000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-50000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-49500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-50500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-50500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-50000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-51000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-50500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-51500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-51500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-51000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-52000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-51500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1519\n","  Batch size = 16\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ok seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: dif seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: del seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-52500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-52500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-52000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-53000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-52500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-53500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-53500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-53000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-54000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-53500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-54500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-54500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-54000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-55000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-54500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-55500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-55500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-55000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-56000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-55500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-56500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-56500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-56000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-57000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-56500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-57500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-57500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-57000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-58000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-57500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-58500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-58500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-58000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-59000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-58500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-59500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-59500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-59000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-60000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-59500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-60500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-60500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-60000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-61000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-60500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-61500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-61500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-61000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-62000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-61500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-62500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-62500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-62000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-63000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-62500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-63500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-63500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-63000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-64000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-63500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-64500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-64500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-64000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-65000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-64500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-65500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-65500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-65000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-66000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-65500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-66500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-66500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-66000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-67000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-66500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-67500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-67500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-67000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-68000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-67500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-68500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-68500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-68000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-69000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-68500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-69500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-69500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-69000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-70000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-69500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-70500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-70500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-70000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-71000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-70500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-71500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-71500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-71000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-72000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-71500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-72500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-72500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-72000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-73000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-72500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-73500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-73500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-73000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-74000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-73500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-74500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-74500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-74000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-75000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-74500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-75500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-75500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-75000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-76000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-75500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-76500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-76500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-76000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-77000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-76500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-77500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-77500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-77000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-78000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-77500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-78500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-78500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-78000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-79000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-78500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-79500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-79500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-79000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-80000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-79500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-80500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-80500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-80000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-81000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-80500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-81500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-81500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-81000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-82000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-81500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-82500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-82500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-82000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-83000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-82500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-83500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-83500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-83000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-84000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-83500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-84500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-84500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-84000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-85000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-84500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-85500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-85500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-85000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-86000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-85500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-86500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-86500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-86000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-87000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-86500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-87500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-87500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-87000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-88000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-87500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-88500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-88500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-88000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-89000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-88500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-89500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-89500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-89000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-90000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-89500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-90500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-90500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-90000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-91000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-90500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-91500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-91500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-91000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-92000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-91500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-92500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-92500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-92000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-93000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-92500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-93500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-93500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-93000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-94000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-93500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-94500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-94500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-94000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-95000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-94500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-95500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-95500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-95000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-96000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-95500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-96500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-96500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-96000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-97000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-96500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-97500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-97500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-97000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-98000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-97500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-98500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-98500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-98000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-99000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-98500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-99500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-99500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-99000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-100000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-99500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-100500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-100500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-100000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-101000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-100500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-101500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-101500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-101000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-102000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-101500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-102500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-102500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-102000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-103000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-102500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-103500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-103500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-103000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-104000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-103500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1519\n","  Batch size = 16\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ok seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: dif seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: del seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-104500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-104500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-104000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-105000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-104500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-105500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-105500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-105000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-106000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-105500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-106500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-106500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-106000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-107000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-106500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-107500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-107500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-107000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-108000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-107500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-108500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-108500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-108000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-109000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-108500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-109500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-109500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-109000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-110000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-109500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-110500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-110500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-110000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-111000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-110500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-111500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-111500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-111000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-112000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-111500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-112500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-112500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-112000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-113000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-112500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-113500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-113500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-113000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-114000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-113500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-114500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-114500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-114000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-115000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-114500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-115500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-115500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-115000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-116000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-115500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-116500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-116500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-116000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-117000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-116500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-117500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-117500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-117000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-118000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-117500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-118500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-118500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-118000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-119000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-118500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-119500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-119500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-119000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-120000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-119500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-120500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-120500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-120000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-121000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-120500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-121500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-121500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-121000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-122000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-121500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-122500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-122500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-122000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-123000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-122500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-123500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-123500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-123000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-124000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-123500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-124500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-124500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-124000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-125000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-124500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-125500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-125500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-125000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-126000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-125500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-126500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-126500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-126000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-127000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-126500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-127500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-127500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-127000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-128000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-127500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-128500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-128500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-128000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-129000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-128500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-129500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-129500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-129000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-130000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-129500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-130500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-130500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-130000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-131000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-130500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-131500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-131500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-131000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-132000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-131500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-132500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-132500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-132000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-133000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-132500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-133500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-133500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-133000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-134000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-133500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-134500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-134500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-134000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-135000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-134500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-135500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-135500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-135000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-136000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-135500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-136500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-136500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-136000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-137000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-136500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-137500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-137500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-137000] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-138000\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138000/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138000/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138000/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138000/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-137500] due to args.save_total_limit\n","Saving model checkpoint to xlm-roberta-base-finetuned-error_detection/checkpoint-138500\n","Configuration saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138500/config.json\n","Model weights saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138500/pytorch_model.bin\n","tokenizer config file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138500/tokenizer_config.json\n","Special tokens file saved in xlm-roberta-base-finetuned-error_detection/checkpoint-138500/special_tokens_map.json\n","Deleting older checkpoint [xlm-roberta-base-finetuned-error_detection/checkpoint-138000] due to args.save_total_limit\n"]}],"source":["trainer.train()\n","#model_loaded = AutoModelForSequenceClassification.from_pretrained(\"Trained model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHrPmV9-Op9g"},"outputs":[],"source":["trainer.save_model(\"Trained model 800k\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"mount_file_id":"1WMGl2N9PdJns7FKqsIJSnU4vb6wKarnW","authorship_tag":"ABX9TyOmxDDl7EdJilLIFs/i64Nt"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"28879e3fe3b1488fb785bcbaf584bc1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e82f4fd2213482f8400011a12b518eb","IPY_MODEL_47c4fd7430994099a91fa54f2b6299b0","IPY_MODEL_9839295520e94413ac059f147c382018"],"layout":"IPY_MODEL_c50bac4aa0f1496c8136905e27472117"}},"5e82f4fd2213482f8400011a12b518eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f698468850ca4480910ece2de82b6e1b","placeholder":"​","style":"IPY_MODEL_443955091d994cd9843334c73ff416e6","value":"Downloading config.json: 100%"}},"47c4fd7430994099a91fa54f2b6299b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9582042967a94aaa87113c654744b919","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a5656f4f4714aeda96b1587b7e19146","value":615}},"9839295520e94413ac059f147c382018":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50eaa07232c74de7b76826f1d2275ed7","placeholder":"​","style":"IPY_MODEL_aedc0019b5da460e9c052008f63f7e48","value":" 615/615 [00:00&lt;00:00, 21.1kB/s]"}},"c50bac4aa0f1496c8136905e27472117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f698468850ca4480910ece2de82b6e1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"443955091d994cd9843334c73ff416e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9582042967a94aaa87113c654744b919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a5656f4f4714aeda96b1587b7e19146":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50eaa07232c74de7b76826f1d2275ed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aedc0019b5da460e9c052008f63f7e48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6999ccf23bf4ba7b5c9301d990f901e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43e4f37d63ca4df89aa4b82450519058","IPY_MODEL_48d519949dde44ccbcef3393f76a6658","IPY_MODEL_2ef673b32ce8446bbc5d6362a3c57641"],"layout":"IPY_MODEL_dfab77ae6968406cab4afcb599116377"}},"43e4f37d63ca4df89aa4b82450519058":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4944619a6bc04e31a340e9b3e3700e5b","placeholder":"​","style":"IPY_MODEL_a35a19ce8af3492784190c12c23725f6","value":"Downloading sentencepiece.bpe.model: 100%"}},"48d519949dde44ccbcef3393f76a6658":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3a351e6a0064f6bb5129b2d6946bc52","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79be4808516c4a80b890727534f1aa94","value":5069051}},"2ef673b32ce8446bbc5d6362a3c57641":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_943315f7b7f344839908753c47ab83b9","placeholder":"​","style":"IPY_MODEL_eeba2a1fd053457694dea950a8325656","value":" 4.83M/4.83M [00:00&lt;00:00, 8.22MB/s]"}},"dfab77ae6968406cab4afcb599116377":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4944619a6bc04e31a340e9b3e3700e5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35a19ce8af3492784190c12c23725f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3a351e6a0064f6bb5129b2d6946bc52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79be4808516c4a80b890727534f1aa94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"943315f7b7f344839908753c47ab83b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeba2a1fd053457694dea950a8325656":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a593cd77d7a243ec963da4c0acdad8f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_892b21bb700145559fc7482f5faa9384","IPY_MODEL_0859a9e697e444a2a50213bd85da9449","IPY_MODEL_e936f05dda5b48fb97c6b8ee3a7b5f6f"],"layout":"IPY_MODEL_f168108689174d5baccc2da39ae7b1c7"}},"892b21bb700145559fc7482f5faa9384":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_785b51e6dc844bfb82a09298b850cf3c","placeholder":"​","style":"IPY_MODEL_f069e7e99baa4aa8b91c0087bf22eb54","value":"Downloading tokenizer.json: 100%"}},"0859a9e697e444a2a50213bd85da9449":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8f6bff4a2c34d50a8f045e0f895a025","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_547ca38578fb48f19b4c0f280b9902ab","value":9096718}},"e936f05dda5b48fb97c6b8ee3a7b5f6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78142dddfa0d423191028245e1aedcc4","placeholder":"​","style":"IPY_MODEL_20e3dab7c5d64317ae5069b7f3fcf4e0","value":" 8.68M/8.68M [00:00&lt;00:00, 19.1MB/s]"}},"f168108689174d5baccc2da39ae7b1c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"785b51e6dc844bfb82a09298b850cf3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f069e7e99baa4aa8b91c0087bf22eb54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8f6bff4a2c34d50a8f045e0f895a025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"547ca38578fb48f19b4c0f280b9902ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78142dddfa0d423191028245e1aedcc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20e3dab7c5d64317ae5069b7f3fcf4e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"429b9cfc184d4c85b6aef57da76848fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02b8e4d4fc79451193a21a73f0f656a5","IPY_MODEL_c9c6b451a07340b58f3fb73536e03313","IPY_MODEL_c167ce9ddc9f4733a8b369876c540694"],"layout":"IPY_MODEL_06f402a9bbb44987ad9604f6ea51a4e4"}},"02b8e4d4fc79451193a21a73f0f656a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c67d3853eed246f5a88056615daf36bf","placeholder":"​","style":"IPY_MODEL_ef6062ed8a3a48d182d07f6aaec5f2b0","value":"Downloading data files: 100%"}},"c9c6b451a07340b58f3fb73536e03313":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_808345a14b204a8f9f33c0493ee49a6d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0963e2bd8d8043f68b91d645f00a3624","value":2}},"c167ce9ddc9f4733a8b369876c540694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb4cd8803f5a41008f2a72e0c89e3987","placeholder":"​","style":"IPY_MODEL_f95e8125948a45099aa6d2931eed9a28","value":" 2/2 [00:00&lt;00:00,  3.65it/s]"}},"06f402a9bbb44987ad9604f6ea51a4e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c67d3853eed246f5a88056615daf36bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef6062ed8a3a48d182d07f6aaec5f2b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"808345a14b204a8f9f33c0493ee49a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0963e2bd8d8043f68b91d645f00a3624":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb4cd8803f5a41008f2a72e0c89e3987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f95e8125948a45099aa6d2931eed9a28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb51f8bcc63340a59361d0ab63cdc591":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c3b5ff235ad4507b9f785739ad863c0","IPY_MODEL_d6b44be109fa4f8eaef31cdcabad0674","IPY_MODEL_f6791067b6a2407390d2d3d1f78043cb"],"layout":"IPY_MODEL_43bd55f0170448ba87b3f3810b42c2fd"}},"7c3b5ff235ad4507b9f785739ad863c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e97b03dde7f4832a7169b09a5bf8c87","placeholder":"​","style":"IPY_MODEL_a31387ed7b7e4665a1ca1f4ec45c5e1a","value":"Extracting data files: 100%"}},"d6b44be109fa4f8eaef31cdcabad0674":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c42801e61d4a93a5517770c1968b03","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad21fb9638134373b537c11605abc425","value":2}},"f6791067b6a2407390d2d3d1f78043cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d5cf4f4c9b04f4b855e1c7853bbb0bd","placeholder":"​","style":"IPY_MODEL_d4593bd1787c4cbebc6efc7fdd1a85d6","value":" 2/2 [00:00&lt;00:00, 20.82it/s]"}},"43bd55f0170448ba87b3f3810b42c2fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e97b03dde7f4832a7169b09a5bf8c87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a31387ed7b7e4665a1ca1f4ec45c5e1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c42801e61d4a93a5517770c1968b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad21fb9638134373b537c11605abc425":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d5cf4f4c9b04f4b855e1c7853bbb0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4593bd1787c4cbebc6efc7fdd1a85d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfe16b693e1e413fa6b8a567f039157e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81d94499696348c6840d4cf609bfcf53","IPY_MODEL_47784786ecaf4e1b97f50a48660c4f7e","IPY_MODEL_956584d6c8184b19bc92578a0ad97527"],"layout":"IPY_MODEL_73873319ce95414d9dd1af3504a77a67"}},"81d94499696348c6840d4cf609bfcf53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64aedabc2bb2424e9137e2d59e190f63","placeholder":"​","style":"IPY_MODEL_be89fafa82c34190ab8a53a3a810b6f1","value":"Generating train split: "}},"47784786ecaf4e1b97f50a48660c4f7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fadd0eff9c64eed82c9584a12232a55","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8df04cc4fc084a97acaf9c434bc0d4d8","value":1}},"956584d6c8184b19bc92578a0ad97527":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1999b6fbe97418ba388921c70b35818","placeholder":"​","style":"IPY_MODEL_8575b18e664743cab33f7475fd887400","value":" 833428/0 [03:34&lt;00:00, 3447.70 examples/s]"}},"73873319ce95414d9dd1af3504a77a67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64aedabc2bb2424e9137e2d59e190f63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be89fafa82c34190ab8a53a3a810b6f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fadd0eff9c64eed82c9584a12232a55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8df04cc4fc084a97acaf9c434bc0d4d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1999b6fbe97418ba388921c70b35818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8575b18e664743cab33f7475fd887400":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9a791e0198e4f3192f469c92938a58b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39d0057e90fa489bb20d805903fe1f26","IPY_MODEL_9488ffd9b1bf449591243f22367ee611","IPY_MODEL_12d70e7422214ce2acf516a6b0005618"],"layout":"IPY_MODEL_88ea6d11f0914b2cb09b7199dbf809d8"}},"39d0057e90fa489bb20d805903fe1f26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbf3c61e40e54c15bca45a21e3b7abaa","placeholder":"​","style":"IPY_MODEL_73da85046f0d429b9c88bea4624a14d5","value":"Generating validation split: "}},"9488ffd9b1bf449591243f22367ee611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2be3b2b17414bd6824e4c3c79278115","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_617024cf9cff4720a1b5a8968ad84d65","value":1}},"12d70e7422214ce2acf516a6b0005618":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ce2311df62459085060e4e88f965ad","placeholder":"​","style":"IPY_MODEL_501ade53fb144033bfdf9f359cfaa6ca","value":" 967/0 [00:00&lt;00:00, 5268.64 examples/s]"}},"88ea6d11f0914b2cb09b7199dbf809d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbf3c61e40e54c15bca45a21e3b7abaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73da85046f0d429b9c88bea4624a14d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2be3b2b17414bd6824e4c3c79278115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"617024cf9cff4720a1b5a8968ad84d65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03ce2311df62459085060e4e88f965ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"501ade53fb144033bfdf9f359cfaa6ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ad9be9be4fc4c4ebb82d6ca718c527d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_138d6c4f7cbf47bd90d837e1b92e689b","IPY_MODEL_1e206ef7df2a4ffea00f6c6a16b6cb6f","IPY_MODEL_23a526b49f23434c9feb7bfe0e85b06e"],"layout":"IPY_MODEL_70abcccb6ff2495587c922eb0b194f75"}},"138d6c4f7cbf47bd90d837e1b92e689b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e5ccd5cc0ea48249672db69e0171e6a","placeholder":"​","style":"IPY_MODEL_98c54377767e4d4ba4d94a040eb2ffc6","value":"100%"}},"1e206ef7df2a4ffea00f6c6a16b6cb6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68512c02d2724197a6409339cbb8aa07","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9460bdc23d544608a47bb297649be013","value":2}},"23a526b49f23434c9feb7bfe0e85b06e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c71c557504c48edb5133db70a427a98","placeholder":"​","style":"IPY_MODEL_7fcbc48487204ac597f572e1549af1d5","value":" 2/2 [00:00&lt;00:00, 52.22it/s]"}},"70abcccb6ff2495587c922eb0b194f75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e5ccd5cc0ea48249672db69e0171e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98c54377767e4d4ba4d94a040eb2ffc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68512c02d2724197a6409339cbb8aa07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9460bdc23d544608a47bb297649be013":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c71c557504c48edb5133db70a427a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fcbc48487204ac597f572e1549af1d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc8631dc0d344b048ef734b96b2d75a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2513dec200794a9fb78929457fb533b0","IPY_MODEL_50df7d4bbbe249148babf585e7469637","IPY_MODEL_1a06e2cb4108427f958602f10a0508ac"],"layout":"IPY_MODEL_ea498309b9f24d7c8f41c0bdc18b90b3"}},"2513dec200794a9fb78929457fb533b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41d7492f6f4a4e249b0d3830f4e15e32","placeholder":"​","style":"IPY_MODEL_90737b5e718e4cb9bbf9a6ee5a42ee71","value":"Downloading pytorch_model.bin: 100%"}},"50df7d4bbbe249148babf585e7469637":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0b34427655f46f2a05a4c11bd97c115","max":1115590446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f3b963da7b144aeaf6a5cf62a7a385c","value":1115590446}},"1a06e2cb4108427f958602f10a0508ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d5655a895454323b058931b5662400e","placeholder":"​","style":"IPY_MODEL_2c107eca5f3747dda87ee828cbbada0a","value":" 1.04G/1.04G [00:16&lt;00:00, 64.5MB/s]"}},"ea498309b9f24d7c8f41c0bdc18b90b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41d7492f6f4a4e249b0d3830f4e15e32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90737b5e718e4cb9bbf9a6ee5a42ee71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0b34427655f46f2a05a4c11bd97c115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f3b963da7b144aeaf6a5cf62a7a385c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d5655a895454323b058931b5662400e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c107eca5f3747dda87ee828cbbada0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"066cb7aa7fbb460cbce99fb5f6a8ae92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ae72080dbc846918ccd235faf391ef4","IPY_MODEL_0ab0af85f99144748eb57ca143c680fd","IPY_MODEL_ce78942c3eb8499c8994c2755d4c7c31"],"layout":"IPY_MODEL_998550dc2ba44952a7c04ab5521146ac"}},"4ae72080dbc846918ccd235faf391ef4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f2022651dcc44d3a9fe19b51dcb07f6","placeholder":"​","style":"IPY_MODEL_d98de1d9171441e6a3184f9e5578036f","value":"Downloading builder script: "}},"0ab0af85f99144748eb57ca143c680fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5945adfcfa1451cb3870f00678ddd17","max":2472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9283912d427f4e2ab90c505245eb1c29","value":2472}},"ce78942c3eb8499c8994c2755d4c7c31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbdc89f42e0f45318e4f458f7e7ed0d3","placeholder":"​","style":"IPY_MODEL_20ca672fff9645f4805a6adb20b4cd48","value":" 6.33k/? [00:00&lt;00:00, 182kB/s]"}},"998550dc2ba44952a7c04ab5521146ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f2022651dcc44d3a9fe19b51dcb07f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d98de1d9171441e6a3184f9e5578036f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5945adfcfa1451cb3870f00678ddd17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9283912d427f4e2ab90c505245eb1c29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbdc89f42e0f45318e4f458f7e7ed0d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20ca672fff9645f4805a6adb20b4cd48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}